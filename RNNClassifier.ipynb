{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import root_numpy as rnpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build here the keras model\n",
    "def RNN_classifier():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(32, input_shape = (None, 8)))\n",
    "    \n",
    "    # make an output layer with just 1 output -> for a binary classification problem: b-jet / not b-jet\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_training_data(jet_list, label):\n",
    "    # extract the tracks and put them in pt-order, hardest tracks first\n",
    "    jet_tracks = [cur[-1] for cur in jet_list]\n",
    "    jet_tracks = [sorted(cur, key = lambda tracks: tracks[0], reverse = True) for cur in jet_tracks]\n",
    "    \n",
    "    # zero-pad the track dimension, to make sure all jets fed into the network during training have the same length\n",
    "    max_tracks = max([len(cur) for cur in jet_tracks])\n",
    "    padded = [np.vstack([cur, np.full((max_tracks - len(cur), 8), 0, float)]) for cur in jet_tracks]\n",
    "    \n",
    "    batch_size = len(padded)\n",
    "    timestep_size = max_tracks\n",
    "    jet_dim = 8\n",
    "    x_train = np.array(padded).reshape(batch_size, timestep_size, jet_dim)\n",
    "    y_train = np.full((batch_size, 1), 1, float) # all are b-jets!\n",
    "    \n",
    "    return x_train, y_train, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size_jets = 10\n",
    "batch_size_tracks = 50\n",
    "read_pos_jets = 0\n",
    "read_pos_tracks = 0\n",
    "number_chunks = 0\n",
    "chunks_limit = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/swshare/anaconda/lib/python2.7/site-packages/root_numpy/_tree.py:209: RuntimeWarning: ignoring duplicate branch named 'Track_nHitPixel'\n",
      "  warn_missing_tree)\n"
     ]
    }
   ],
   "source": [
    "while number_chunks < chunks_limit:\n",
    "    number_chunks += 1\n",
    "    \n",
    "    # read in new chunk of jet and track data\n",
    "    d1 = pd.DataFrame(rnpy.root2array(\"/mnt/t3nfs01/data01/shome/jpata/btv/gc/TagVarExtractor/GCa08e5e237323/TT_TuneCUETP8M1_13TeV-powheg-pythia8/job_0_out.root\",\n",
    "                                 treename = \"tagVars/ttree\", start = read_pos_jets, stop = read_pos_jets + batch_size_jets))\n",
    "    d2 = pd.DataFrame(rnpy.root2array(\"/mnt/t3nfs01/data01/shome/jpata/btv/gc/TagVarExtractor/GCa08e5e237323/TT_TuneCUETP8M1_13TeV-powheg-pythia8/job_0_out.root\",\n",
    "                                 treename = \"tagVars/ttree_track\", start = read_pos_tracks, stop = read_pos_tracks + batch_size_tracks))\n",
    "    \n",
    "    # figure out where the next chunk should start so that we don't count any jets multiple times\n",
    "    last_tracks = (int)(d2.tail(1)['Track_jetIndex'].iloc[0]-1)\n",
    "    last_jet = (int)(d1.tail(1)['Jet_jetIndex'].iloc[0]-1)\n",
    "    read_pos_jets += (d1.loc[d1['Jet_jetIndex'] == last_tracks].index[-1] + 1)\n",
    "    read_pos_tracks += (d2.loc[d2['Track_jetIndex'] == last_tracks].index[-1] + 1)\n",
    "\n",
    "    # add the track data to the jet list\n",
    "    d1['track_data'] = pd.np.empty((len(d1.index),0)).tolist()\n",
    "    \n",
    "    # iterate over the track list to join jets with the tracks belonging to them\n",
    "    for irow, row in d2.iterrows():\n",
    "        # these are the track data of the current track:\n",
    "        tracks = row[[\"Track_pt\", \"Track_eta\", \"Track_phi\", \"Track_dxy\", \"Track_dz\", \"Track_IP\", \"Track_IP2D\", \"Track_length\"]].as_matrix()\n",
    "        jet_index = int(row[\"Track_jetIndex\"])\n",
    "        if jet_index > last_tracks:\n",
    "            break\n",
    "        table_index = d1.loc[d1['Jet_jetIndex'] == jet_index].index[0]\n",
    "\n",
    "        # append the tracks data to the matching jet in the main table\n",
    "        d1['track_data'][table_index].append(tracks)\n",
    "    \n",
    "    # now divide the jets and put them in separate lists, according to their flavour\n",
    "    jets_b = []\n",
    "    jets_l = []\n",
    "    jets_c = []\n",
    "\n",
    "    # iterate over the jet list, with already matched tracks\n",
    "    for irow, row in d1.iterrows():\n",
    "        jet_index = int(row[\"Jet_jetIndex\"])\n",
    "        if jet_index > last_tracks:\n",
    "            break\n",
    "\n",
    "        flavour = int(row[\"Jet_flavour\"])\n",
    "\n",
    "        # select the right list this jet belongs to\n",
    "        if abs(flavour) == 5:\n",
    "            jets = jets_b\n",
    "        elif abs(flavour) == 4:\n",
    "            jets = jets_c\n",
    "        else:\n",
    "            jets = jets_l\n",
    "\n",
    "        # add the new jet to the list\n",
    "        jets += [(row[\"Jet_pt\"], row[\"Jet_eta\"], row[\"Jet_phi\"], row[\"Jet_mass\"], flavour, row[\"track_data\"])]\n",
    "        \n",
    "    # now, have sorted jets in three lists, can use them directly for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, y_train, batch_size = prepare_training_data(jets_b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RNN_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s - loss: 0.8104 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s - loss: 0.7773 - acc: 0.3333\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s - loss: 0.7451 - acc: 0.6667\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s - loss: 0.7137 - acc: 0.6667\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s - loss: 0.6832 - acc: 0.6667\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s - loss: 0.6536 - acc: 0.6667\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s - loss: 0.6250 - acc: 0.6667\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s - loss: 0.5973 - acc: 0.6667\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s - loss: 0.5706 - acc: 0.6667\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s - loss: 0.5449 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f813da4d590>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model after training here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /mnt/t3nfs01/data01/shome/phwindis/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-redhat-6.6-Carbon-x86_64-2.7.12-64/lock_dir/lock\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.37535214]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(b, batch_size = 1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
