loading model back for further training
chunk number 0
prepare data
start training
Train on 8101 samples, validate on 2026 samples
Epoch 1/1
8101/8101 [==============================] - 1s - loss: 0.4182 - acc: 0.8213 - val_loss: 0.4360 - val_acc: 0.8095
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-1.h5
chunk number 1
prepare data
start training
Train on 8112 samples, validate on 2028 samples
Epoch 1/1
8112/8112 [==============================] - 0s - loss: 0.4293 - acc: 0.8114 - val_loss: 0.4193 - val_acc: 0.8210
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-2.h5
chunk number 2
prepare data
start training
Train on 8140 samples, validate on 2035 samples
Epoch 1/1
8140/8140 [==============================] - 0s - loss: 0.4289 - acc: 0.8133 - val_loss: 0.4259 - val_acc: 0.8147
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-3.h5
chunk number 3
prepare data
start training
Train on 8078 samples, validate on 2020 samples
Epoch 1/1
8078/8078 [==============================] - 0s - loss: 0.4345 - acc: 0.8085 - val_loss: 0.4179 - val_acc: 0.8183
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-4.h5
chunk number 4
prepare data
start training
Train on 8116 samples, validate on 2029 samples
Epoch 1/1
8116/8116 [==============================] - 0s - loss: 0.4375 - acc: 0.8074 - val_loss: 0.4058 - val_acc: 0.8324
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-5.h5
chunk number 5
prepare data
start training
Train on 8151 samples, validate on 2038 samples
Epoch 1/1
8151/8151 [==============================] - 0s - loss: 0.4201 - acc: 0.8190 - val_loss: 0.4298 - val_acc: 0.8062
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-6.h5
chunk number 6
prepare data
start training
Train on 8168 samples, validate on 2043 samples
Epoch 1/1
8168/8168 [==============================] - 0s - loss: 0.4162 - acc: 0.8233 - val_loss: 0.4246 - val_acc: 0.8194
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-7.h5
chunk number 7
prepare data
start training
Train on 8119 samples, validate on 2030 samples
Epoch 1/1
8119/8119 [==============================] - 0s - loss: 0.4217 - acc: 0.8181 - val_loss: 0.3997 - val_acc: 0.8296
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-8.h5
chunk number 8
prepare data
start training
Train on 8100 samples, validate on 2026 samples
Epoch 1/1
8100/8100 [==============================] - 0s - loss: 0.4224 - acc: 0.8152 - val_loss: 0.4192 - val_acc: 0.8243
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-9.h5
chunk number 9
prepare data
start training
Train on 8150 samples, validate on 2038 samples
Epoch 1/1
8150/8150 [==============================] - 0s - loss: 0.4142 - acc: 0.8187 - val_loss: 0.4084 - val_acc: 0.8268
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-10.h5
chunk number 10
prepare data
start training
Train on 8056 samples, validate on 2014 samples
Epoch 1/1
8056/8056 [==============================] - 0s - loss: 0.4266 - acc: 0.8136 - val_loss: 0.4371 - val_acc: 0.8073
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-11.h5
chunk number 11
prepare data
start training
Train on 8118 samples, validate on 2030 samples
Epoch 1/1
8118/8118 [==============================] - 0s - loss: 0.4283 - acc: 0.8102 - val_loss: 0.4202 - val_acc: 0.8187
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-12.h5
chunk number 12
prepare data
start training
Train on 8088 samples, validate on 2023 samples
Epoch 1/1
8088/8088 [==============================] - 0s - loss: 0.4327 - acc: 0.8108 - val_loss: 0.4193 - val_acc: 0.8216
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-13.h5
chunk number 13
prepare data
start training
Train on 8109 samples, validate on 2028 samples
Epoch 1/1
8109/8109 [==============================] - 0s - loss: 0.4157 - acc: 0.8228 - val_loss: 0.4019 - val_acc: 0.8230
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-14.h5
chunk number 14
prepare data
start training
Train on 8067 samples, validate on 2017 samples
Epoch 1/1
8067/8067 [==============================] - 0s - loss: 0.4186 - acc: 0.8183 - val_loss: 0.4389 - val_acc: 0.7997
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-15.h5
chunk number 15
prepare data
start training
Train on 8109 samples, validate on 2028 samples
Epoch 1/1
8109/8109 [==============================] - 0s - loss: 0.4159 - acc: 0.8214 - val_loss: 0.4281 - val_acc: 0.8185
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-16.h5
chunk number 16
prepare data
start training
Train on 8150 samples, validate on 2038 samples
Epoch 1/1
8150/8150 [==============================] - 0s - loss: 0.4156 - acc: 0.8167 - val_loss: 0.4180 - val_acc: 0.8209
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-17.h5
chunk number 17
prepare data
start training
Train on 8048 samples, validate on 2013 samples
Epoch 1/1
8048/8048 [==============================] - 0s - loss: 0.4195 - acc: 0.8197 - val_loss: 0.4184 - val_acc: 0.8162
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-18.h5
chunk number 18
prepare data
start training
Train on 8149 samples, validate on 2038 samples
Epoch 1/1
8149/8149 [==============================] - 0s - loss: 0.4152 - acc: 0.8221 - val_loss: 0.4235 - val_acc: 0.8116
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-19.h5
chunk number 19
prepare data
start training
Train on 8063 samples, validate on 2016 samples
Epoch 1/1
8063/8063 [==============================] - 0s - loss: 0.4190 - acc: 0.8198 - val_loss: 0.4211 - val_acc: 0.8150
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-20.h5
chunk number 20
prepare data
start training
Train on 8012 samples, validate on 2003 samples
Epoch 1/1
8012/8012 [==============================] - 0s - loss: 0.4202 - acc: 0.8235 - val_loss: 0.4186 - val_acc: 0.8238
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-21.h5
chunk number 21
prepare data
start training
Train on 8136 samples, validate on 2035 samples
Epoch 1/1
8136/8136 [==============================] - 0s - loss: 0.4123 - acc: 0.8226 - val_loss: 0.4201 - val_acc: 0.8172
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-22.h5
chunk number 22
prepare data
start training
Train on 8154 samples, validate on 2039 samples
Epoch 1/1
8154/8154 [==============================] - 0s - loss: 0.4084 - acc: 0.8238 - val_loss: 0.4165 - val_acc: 0.8254
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-23.h5
chunk number 23
prepare data
start training
Train on 8120 samples, validate on 2031 samples
Epoch 1/1
8120/8120 [==============================] - 0s - loss: 0.4293 - acc: 0.8151 - val_loss: 0.4576 - val_acc: 0.8031
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-24.h5
chunk number 24
prepare data
start training
Train on 8105 samples, validate on 2027 samples
Epoch 1/1
8105/8105 [==============================] - 0s - loss: 0.4253 - acc: 0.8149 - val_loss: 0.4240 - val_acc: 0.8101
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-25.h5
chunk number 25
prepare data
start training
Train on 8148 samples, validate on 2037 samples
Epoch 1/1
8148/8148 [==============================] - 0s - loss: 0.4155 - acc: 0.8185 - val_loss: 0.4194 - val_acc: 0.8203
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-26.h5
chunk number 26
prepare data
start training
Train on 8063 samples, validate on 2016 samples
Epoch 1/1
8063/8063 [==============================] - 0s - loss: 0.4209 - acc: 0.8225 - val_loss: 0.4370 - val_acc: 0.8061
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-27.h5
chunk number 27
prepare data
start training
Train on 8080 samples, validate on 2020 samples
Epoch 1/1
8080/8080 [==============================] - 0s - loss: 0.4207 - acc: 0.8212 - val_loss: 0.4189 - val_acc: 0.8163
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-28.h5
chunk number 28
prepare data
start training
Train on 8152 samples, validate on 2039 samples
Epoch 1/1
8152/8152 [==============================] - 0s - loss: 0.4204 - acc: 0.8194 - val_loss: 0.4152 - val_acc: 0.8205
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-29.h5
chunk number 29
prepare data
start training
Train on 8164 samples, validate on 2041 samples
Epoch 1/1
8164/8164 [==============================] - 0s - loss: 0.4350 - acc: 0.8123 - val_loss: 0.4296 - val_acc: 0.8133
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-30.h5
chunk number 30
prepare data
start training
Train on 8088 samples, validate on 2022 samples
Epoch 1/1
8088/8088 [==============================] - 0s - loss: 0.4376 - acc: 0.8119 - val_loss: 0.4324 - val_acc: 0.8131
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-31.h5
chunk number 31
prepare data
start training
Train on 8228 samples, validate on 2058 samples
Epoch 1/1
8228/8228 [==============================] - 0s - loss: 0.4419 - acc: 0.8047 - val_loss: 0.4224 - val_acc: 0.8231
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-32.h5
chunk number 32
prepare data
start training
Train on 8221 samples, validate on 2056 samples
Epoch 1/1
8221/8221 [==============================] - 0s - loss: 0.4411 - acc: 0.8049 - val_loss: 0.4299 - val_acc: 0.8196
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-33.h5
chunk number 33
prepare data
start training
Train on 8144 samples, validate on 2037 samples
Epoch 1/1
8144/8144 [==============================] - 0s - loss: 0.4217 - acc: 0.8200 - val_loss: 0.4476 - val_acc: 0.7992
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-34.h5
chunk number 34
prepare data
start training
Train on 8203 samples, validate on 2051 samples
Epoch 1/1
8203/8203 [==============================] - 0s - loss: 0.4475 - acc: 0.8028 - val_loss: 0.4826 - val_acc: 0.7913
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-35.h5
chunk number 35
prepare data
start training
Train on 8209 samples, validate on 2053 samples
Epoch 1/1
8209/8209 [==============================] - 0s - loss: 0.4360 - acc: 0.8107 - val_loss: 0.4500 - val_acc: 0.8047
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-36.h5
chunk number 36
prepare data
start training
Train on 8060 samples, validate on 2016 samples
Epoch 1/1
8060/8060 [==============================] - 0s - loss: 0.4620 - acc: 0.7959 - val_loss: 0.4344 - val_acc: 0.8036
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-37.h5
chunk number 37
prepare data
start training
Train on 8159 samples, validate on 2040 samples
Epoch 1/1
8159/8159 [==============================] - 0s - loss: 0.4678 - acc: 0.7967 - val_loss: 0.4537 - val_acc: 0.8025
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-38.h5
chunk number 38
prepare data
start training
Train on 8143 samples, validate on 2036 samples
Epoch 1/1
8143/8143 [==============================] - 0s - loss: 0.4441 - acc: 0.8101 - val_loss: 0.4659 - val_acc: 0.7868
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-39.h5
chunk number 39
prepare data
start training
Train on 8130 samples, validate on 2033 samples
Epoch 1/1
8130/8130 [==============================] - 0s - loss: 0.4765 - acc: 0.7844 - val_loss: 0.4181 - val_acc: 0.8239
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-40.h5
chunk number 40
prepare data
start training
Train on 8148 samples, validate on 2037 samples
Epoch 1/1
8148/8148 [==============================] - 0s - loss: 0.4410 - acc: 0.8141 - val_loss: 0.4649 - val_acc: 0.7992
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-41.h5
chunk number 41
prepare data
start training
Train on 8140 samples, validate on 2036 samples
Epoch 1/1
8140/8140 [==============================] - 0s - loss: 0.4356 - acc: 0.8104 - val_loss: 0.4411 - val_acc: 0.8001
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-42.h5
chunk number 42
prepare data
start training
Train on 8142 samples, validate on 2036 samples
Epoch 1/1
8142/8142 [==============================] - 0s - loss: 0.4446 - acc: 0.8018 - val_loss: 0.4410 - val_acc: 0.8016
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-43.h5
chunk number 43
prepare data
start training
Train on 8175 samples, validate on 2044 samples
Epoch 1/1
8175/8175 [==============================] - 0s - loss: 0.4185 - acc: 0.8203 - val_loss: 0.4596 - val_acc: 0.8019
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-44.h5
chunk number 44
prepare data
start training
Train on 8076 samples, validate on 2020 samples
Epoch 1/1
8076/8076 [==============================] - 0s - loss: 0.4425 - acc: 0.8139 - val_loss: 0.4411 - val_acc: 0.8114
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-45.h5
chunk number 45
prepare data
start training
Train on 8216 samples, validate on 2054 samples
Epoch 1/1
8216/8216 [==============================] - 0s - loss: 0.4265 - acc: 0.8171 - val_loss: 0.4067 - val_acc: 0.8228
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-46.h5
chunk number 46
prepare data
start training
Train on 8084 samples, validate on 2021 samples
Epoch 1/1
8084/8084 [==============================] - 0s - loss: 0.4254 - acc: 0.8193 - val_loss: 0.4207 - val_acc: 0.8248
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-47.h5
chunk number 47
prepare data
start training
Train on 8087 samples, validate on 2022 samples
Epoch 1/1
8087/8087 [==============================] - 0s - loss: 0.4238 - acc: 0.8201 - val_loss: 0.3899 - val_acc: 0.8323
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-48.h5
chunk number 48
prepare data
start training
Train on 8114 samples, validate on 2029 samples
Epoch 1/1
8114/8114 [==============================] - 0s - loss: 0.4265 - acc: 0.8243 - val_loss: 0.4200 - val_acc: 0.8186
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-49.h5
chunk number 49
prepare data
start training
Train on 8180 samples, validate on 2046 samples
Epoch 1/1
8180/8180 [==============================] - 0s - loss: 0.4260 - acc: 0.8152 - val_loss: 0.4268 - val_acc: 0.8065
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-50.h5
chunk number 50
prepare data
start training
Train on 8216 samples, validate on 2054 samples
Epoch 1/1
8216/8216 [==============================] - 0s - loss: 0.4254 - acc: 0.8161 - val_loss: 0.4329 - val_acc: 0.8106
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-51.h5
chunk number 51
prepare data
start training
Train on 8096 samples, validate on 2024 samples
Epoch 1/1
8096/8096 [==============================] - 0s - loss: 0.4308 - acc: 0.8102 - val_loss: 0.4340 - val_acc: 0.8177
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-52.h5
chunk number 52
prepare data
start training
Train on 8141 samples, validate on 2036 samples
Epoch 1/1
8141/8141 [==============================] - 0s - loss: 0.4344 - acc: 0.8142 - val_loss: 0.4145 - val_acc: 0.8242
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-53.h5
chunk number 53
prepare data
start training
Train on 8188 samples, validate on 2047 samples
Epoch 1/1
8188/8188 [==============================] - 0s - loss: 0.4360 - acc: 0.8120 - val_loss: 0.4348 - val_acc: 0.8100
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-54.h5
chunk number 54
prepare data
start training
Train on 8091 samples, validate on 2023 samples
Epoch 1/1
8091/8091 [==============================] - 0s - loss: 0.4081 - acc: 0.8245 - val_loss: 0.4254 - val_acc: 0.8166
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-55.h5
chunk number 55
prepare data
start training
Train on 8229 samples, validate on 2058 samples
Epoch 1/1
8229/8229 [==============================] - 0s - loss: 0.4202 - acc: 0.8210 - val_loss: 0.4055 - val_acc: 0.8358
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-56.h5
chunk number 56
prepare data
start training
Train on 8088 samples, validate on 2023 samples
Epoch 1/1
8088/8088 [==============================] - 0s - loss: 0.4198 - acc: 0.8234 - val_loss: 0.4108 - val_acc: 0.8220
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-57.h5
chunk number 57
prepare data
start training
Train on 8234 samples, validate on 2059 samples
Epoch 1/1
8234/8234 [==============================] - 0s - loss: 0.4170 - acc: 0.8201 - val_loss: 0.4100 - val_acc: 0.8344
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-58.h5
chunk number 58
prepare data
start training
Train on 8077 samples, validate on 2020 samples
Epoch 1/1
8077/8077 [==============================] - 0s - loss: 0.4253 - acc: 0.8212 - val_loss: 0.4349 - val_acc: 0.8069
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-59.h5
chunk number 59
prepare data
start training
Train on 8202 samples, validate on 2051 samples
Epoch 1/1
8202/8202 [==============================] - 0s - loss: 0.4267 - acc: 0.8236 - val_loss: 0.4445 - val_acc: 0.7967
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-60.h5
chunk number 60
prepare data
start training
Train on 8172 samples, validate on 2044 samples
Epoch 1/1
8172/8172 [==============================] - 0s - loss: 0.4623 - acc: 0.7949 - val_loss: 0.4058 - val_acc: 0.8141
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-61.h5
chunk number 61
prepare data
start training
Train on 8139 samples, validate on 2035 samples
Epoch 1/1
8139/8139 [==============================] - 0s - loss: 0.4214 - acc: 0.8218 - val_loss: 0.4582 - val_acc: 0.8059
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-62.h5
chunk number 62
prepare data
start training
Train on 8076 samples, validate on 2020 samples
Epoch 1/1
8076/8076 [==============================] - 0s - loss: 0.4230 - acc: 0.8171 - val_loss: 0.4501 - val_acc: 0.7985
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-63.h5
chunk number 63
prepare data
start training
Train on 8184 samples, validate on 2046 samples
Epoch 1/1
8184/8184 [==============================] - 0s - loss: 0.4450 - acc: 0.8091 - val_loss: 0.4423 - val_acc: 0.8079
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-64.h5
chunk number 64
prepare data
start training
Train on 8099 samples, validate on 2025 samples
Epoch 1/1
8099/8099 [==============================] - 0s - loss: 0.4331 - acc: 0.8091 - val_loss: 0.4283 - val_acc: 0.8168
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-65.h5
chunk number 65
prepare data
start training
Train on 8174 samples, validate on 2044 samples
Epoch 1/1
8174/8174 [==============================] - 0s - loss: 0.4374 - acc: 0.8172 - val_loss: 0.4429 - val_acc: 0.8175
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-66.h5
chunk number 66
prepare data
start training
Train on 8196 samples, validate on 2050 samples
Epoch 1/1
8196/8196 [==============================] - 0s - loss: 0.4425 - acc: 0.8183 - val_loss: 0.4235 - val_acc: 0.8180
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-67.h5
chunk number 67
prepare data
start training
Train on 8059 samples, validate on 2015 samples
Epoch 1/1
8059/8059 [==============================] - 0s - loss: 0.4198 - acc: 0.8202 - val_loss: 0.4391 - val_acc: 0.8074
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-68.h5
chunk number 68
prepare data
start training
Train on 8099 samples, validate on 2025 samples
Epoch 1/1
8099/8099 [==============================] - 0s - loss: 0.4230 - acc: 0.8141 - val_loss: 0.4191 - val_acc: 0.8188
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-69.h5
chunk number 69
prepare data
start training
Train on 8125 samples, validate on 2032 samples
Epoch 1/1
8125/8125 [==============================] - 0s - loss: 0.4434 - acc: 0.8071 - val_loss: 0.4286 - val_acc: 0.8081
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-70.h5
chunk number 70
prepare data
start training
Train on 8145 samples, validate on 2037 samples
Epoch 1/1
8145/8145 [==============================] - 0s - loss: 0.4287 - acc: 0.8184 - val_loss: 0.4147 - val_acc: 0.8174
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-71.h5
chunk number 71
prepare data
start training
Train on 8144 samples, validate on 2036 samples
Epoch 1/1
8144/8144 [==============================] - 0s - loss: 0.4232 - acc: 0.8202 - val_loss: 0.4260 - val_acc: 0.8242
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-72.h5
chunk number 72
prepare data
start training
Train on 8096 samples, validate on 2025 samples
Epoch 1/1
8096/8096 [==============================] - 0s - loss: 0.4363 - acc: 0.8169 - val_loss: 0.4145 - val_acc: 0.8262
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-73.h5
chunk number 73
prepare data
start training
Train on 8158 samples, validate on 2040 samples
Epoch 1/1
8158/8158 [==============================] - 0s - loss: 0.4114 - acc: 0.8252 - val_loss: 0.4188 - val_acc: 0.8176
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-74.h5
chunk number 74
prepare data
start training
Train on 8055 samples, validate on 2014 samples
Epoch 1/1
8055/8055 [==============================] - 0s - loss: 0.4261 - acc: 0.8106 - val_loss: 0.4504 - val_acc: 0.8078
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-75.h5
chunk number 75
prepare data
start training
Train on 8119 samples, validate on 2030 samples
Epoch 1/1
8119/8119 [==============================] - 0s - loss: 0.4283 - acc: 0.8120 - val_loss: 0.4218 - val_acc: 0.8133
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-76.h5
chunk number 76
prepare data
start training
Train on 8104 samples, validate on 2027 samples
Epoch 1/1
8104/8104 [==============================] - 0s - loss: 0.4211 - acc: 0.8155 - val_loss: 0.4230 - val_acc: 0.8180
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-77.h5
chunk number 77
prepare data
start training
Train on 8164 samples, validate on 2042 samples
Epoch 1/1
8164/8164 [==============================] - 0s - loss: 0.4129 - acc: 0.8247 - val_loss: 0.4136 - val_acc: 0.8159
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-78.h5
chunk number 78
prepare data
start training
Train on 8179 samples, validate on 2045 samples
Epoch 1/1
8179/8179 [==============================] - 0s - loss: 0.4218 - acc: 0.8201 - val_loss: 0.4171 - val_acc: 0.8142
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-79.h5
chunk number 79
prepare data
start training
Train on 8154 samples, validate on 2039 samples
Epoch 1/1
8154/8154 [==============================] - 0s - loss: 0.4034 - acc: 0.8243 - val_loss: 0.4282 - val_acc: 0.8195
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-80.h5
chunk number 80
prepare data
start training
Train on 8148 samples, validate on 2038 samples
Epoch 1/1
8148/8148 [==============================] - 0s - loss: 0.4250 - acc: 0.8157 - val_loss: 0.4233 - val_acc: 0.8224
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-81.h5
chunk number 81
prepare data
start training
Train on 8107 samples, validate on 2027 samples
Epoch 1/1
8107/8107 [==============================] - 0s - loss: 0.4205 - acc: 0.8176 - val_loss: 0.4105 - val_acc: 0.8175
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-82.h5
chunk number 82
prepare data
start training
Train on 8011 samples, validate on 2003 samples
Epoch 1/1
8011/8011 [==============================] - 0s - loss: 0.4151 - acc: 0.8204 - val_loss: 0.4194 - val_acc: 0.8128
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-83.h5
chunk number 83
prepare data
start training
Train on 8082 samples, validate on 2021 samples
Epoch 1/1
8082/8082 [==============================] - 0s - loss: 0.4133 - acc: 0.8263 - val_loss: 0.4154 - val_acc: 0.8204
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-84.h5
chunk number 84
prepare data
start training
Train on 8112 samples, validate on 2029 samples
Epoch 1/1
8112/8112 [==============================] - 0s - loss: 0.4167 - acc: 0.8233 - val_loss: 0.4099 - val_acc: 0.8201
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-85.h5
chunk number 85
prepare data
start training
Train on 8201 samples, validate on 2051 samples
Epoch 1/1
8201/8201 [==============================] - 0s - loss: 0.4124 - acc: 0.8203 - val_loss: 0.4335 - val_acc: 0.8176
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-86.h5
chunk number 86
prepare data
start training
Train on 8187 samples, validate on 2047 samples
Epoch 1/1
8187/8187 [==============================] - 0s - loss: 0.4121 - acc: 0.8217 - val_loss: 0.3950 - val_acc: 0.8285
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-87.h5
chunk number 87
prepare data
start training
Train on 8162 samples, validate on 2041 samples
Epoch 1/1
8162/8162 [==============================] - 0s - loss: 0.4072 - acc: 0.8292 - val_loss: 0.4339 - val_acc: 0.8084
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-88.h5
chunk number 88
prepare data
start training
Train on 8134 samples, validate on 2034 samples
Epoch 1/1
8134/8134 [==============================] - 0s - loss: 0.4073 - acc: 0.8257 - val_loss: 0.4226 - val_acc: 0.8191
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-89.h5
chunk number 89
prepare data
start training
Train on 8090 samples, validate on 2023 samples
Epoch 1/1
8090/8090 [==============================] - 0s - loss: 0.4318 - acc: 0.8183 - val_loss: 0.4191 - val_acc: 0.8270
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-90.h5
chunk number 90
prepare data
start training
Train on 8245 samples, validate on 2062 samples
Epoch 1/1
8245/8245 [==============================] - 0s - loss: 0.4301 - acc: 0.8136 - val_loss: 0.4203 - val_acc: 0.8167
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-91.h5
chunk number 91
prepare data
start training
Train on 8067 samples, validate on 2017 samples
Epoch 1/1
8067/8067 [==============================] - 0s - loss: 0.4293 - acc: 0.8143 - val_loss: 0.4295 - val_acc: 0.8180
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-92.h5
chunk number 92
prepare data
start training
Train on 8117 samples, validate on 2030 samples
Epoch 1/1
8117/8117 [==============================] - 0s - loss: 0.4138 - acc: 0.8209 - val_loss: 0.4369 - val_acc: 0.8089
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-93.h5
chunk number 93
prepare data
start training
Train on 8140 samples, validate on 2035 samples
Epoch 1/1
8140/8140 [==============================] - 0s - loss: 0.4391 - acc: 0.8124 - val_loss: 0.4022 - val_acc: 0.8221
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-94.h5
chunk number 94
prepare data
start training
Train on 8072 samples, validate on 2018 samples
Epoch 1/1
8072/8072 [==============================] - 0s - loss: 0.4145 - acc: 0.8280 - val_loss: 0.4129 - val_acc: 0.8176
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-95.h5
chunk number 95
prepare data
start training
Train on 8092 samples, validate on 2024 samples
Epoch 1/1
8092/8092 [==============================] - 0s - loss: 0.4134 - acc: 0.8211 - val_loss: 0.4423 - val_acc: 0.8058
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-96.h5
chunk number 96
prepare data
start training
Train on 8128 samples, validate on 2033 samples
Epoch 1/1
8128/8128 [==============================] - 0s - loss: 0.4367 - acc: 0.8107 - val_loss: 0.4025 - val_acc: 0.8244
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-97.h5
chunk number 97
prepare data
start training
Train on 8037 samples, validate on 2010 samples
Epoch 1/1
8037/8037 [==============================] - 0s - loss: 0.4157 - acc: 0.8226 - val_loss: 0.4137 - val_acc: 0.8239
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-98.h5
chunk number 98
prepare data
start training
Train on 8188 samples, validate on 2047 samples
Epoch 1/1
8188/8188 [==============================] - 0s - loss: 0.4205 - acc: 0.8168 - val_loss: 0.4323 - val_acc: 0.8080
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-99.h5
chunk number 99
prepare data
start training
Train on 8163 samples, validate on 2041 samples
Epoch 1/1
8163/8163 [==============================] - 0s - loss: 0.4183 - acc: 0.8227 - val_loss: 0.4271 - val_acc: 0.8138
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-100.h5
chunk number 100
prepare data
start training
Train on 8208 samples, validate on 2052 samples
Epoch 1/1
8208/8208 [==============================] - 0s - loss: 0.4202 - acc: 0.8170 - val_loss: 0.4297 - val_acc: 0.8143
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-101.h5
chunk number 101
prepare data
start training
Train on 8128 samples, validate on 2032 samples
Epoch 1/1
8128/8128 [==============================] - 0s - loss: 0.4258 - acc: 0.8136 - val_loss: 0.4282 - val_acc: 0.8120
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-102.h5
chunk number 102
prepare data
start training
Train on 8131 samples, validate on 2033 samples
Epoch 1/1
8131/8131 [==============================] - 0s - loss: 0.4191 - acc: 0.8191 - val_loss: 0.4024 - val_acc: 0.8323
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-103.h5
chunk number 103
prepare data
start training
Train on 8113 samples, validate on 2029 samples
Epoch 1/1
8113/8113 [==============================] - 0s - loss: 0.4142 - acc: 0.8237 - val_loss: 0.4194 - val_acc: 0.8147
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-104.h5
chunk number 104
prepare data
start training
Train on 8206 samples, validate on 2052 samples
Epoch 1/1
8206/8206 [==============================] - 0s - loss: 0.4060 - acc: 0.8335 - val_loss: 0.4151 - val_acc: 0.8255
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-105.h5
chunk number 105
prepare data
start training
Train on 8129 samples, validate on 2033 samples
Epoch 1/1
8129/8129 [==============================] - 0s - loss: 0.4109 - acc: 0.8259 - val_loss: 0.4265 - val_acc: 0.8111
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-106.h5
chunk number 106
prepare data
start training
Train on 8087 samples, validate on 2022 samples
Epoch 1/1
8087/8087 [==============================] - 0s - loss: 0.4201 - acc: 0.8181 - val_loss: 0.4107 - val_acc: 0.8220
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-107.h5
chunk number 107
prepare data
start training
Train on 8177 samples, validate on 2045 samples
Epoch 1/1
8177/8177 [==============================] - 0s - loss: 0.4112 - acc: 0.8238 - val_loss: 0.4075 - val_acc: 0.8230
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-108.h5
chunk number 108
prepare data
start training
Train on 8212 samples, validate on 2054 samples
Epoch 1/1
8212/8212 [==============================] - 0s - loss: 0.4141 - acc: 0.8229 - val_loss: 0.4282 - val_acc: 0.8121
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-109.h5
chunk number 109
prepare data
start training
Train on 8164 samples, validate on 2041 samples
Epoch 1/1
8164/8164 [==============================] - 0s - loss: 0.4179 - acc: 0.8182 - val_loss: 0.4055 - val_acc: 0.8197
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-110.h5
chunk number 110
prepare data
start training
Train on 8110 samples, validate on 2028 samples
Epoch 1/1
8110/8110 [==============================] - 0s - loss: 0.4211 - acc: 0.8166 - val_loss: 0.4180 - val_acc: 0.8136
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-111.h5
chunk number 111
prepare data
start training
Train on 8038 samples, validate on 2010 samples
Epoch 1/1
8038/8038 [==============================] - 0s - loss: 0.4119 - acc: 0.8228 - val_loss: 0.4248 - val_acc: 0.8214
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-112.h5
chunk number 112
prepare data
start training
Train on 8172 samples, validate on 2044 samples
Epoch 1/1
8172/8172 [==============================] - 0s - loss: 0.4103 - acc: 0.8185 - val_loss: 0.3858 - val_acc: 0.8356
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-113.h5
chunk number 113
prepare data
start training
Train on 8224 samples, validate on 2057 samples
Epoch 1/1
8224/8224 [==============================] - 0s - loss: 0.4124 - acc: 0.8214 - val_loss: 0.3993 - val_acc: 0.8264
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-114.h5
chunk number 114
prepare data
start training
Train on 8148 samples, validate on 2038 samples
Epoch 1/1
8148/8148 [==============================] - 0s - loss: 0.4179 - acc: 0.8204 - val_loss: 0.4053 - val_acc: 0.8283
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-115.h5
chunk number 115
prepare data
start training
Train on 8130 samples, validate on 2033 samples
Epoch 1/1
8130/8130 [==============================] - 0s - loss: 0.4102 - acc: 0.8239 - val_loss: 0.4321 - val_acc: 0.8151
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-116.h5
chunk number 116
prepare data
start training
Train on 8085 samples, validate on 2022 samples
Epoch 1/1
8085/8085 [==============================] - 0s - loss: 0.4165 - acc: 0.8224 - val_loss: 0.4201 - val_acc: 0.8234
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-117.h5
chunk number 117
prepare data
start training
Train on 8172 samples, validate on 2043 samples
Epoch 1/1
8172/8172 [==============================] - 0s - loss: 0.4226 - acc: 0.8173 - val_loss: 0.3907 - val_acc: 0.8390
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-118.h5
chunk number 118
prepare data
start training
Train on 8184 samples, validate on 2047 samples
Epoch 1/1
8184/8184 [==============================] - 0s - loss: 0.4257 - acc: 0.8130 - val_loss: 0.4155 - val_acc: 0.8212
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-119.h5
chunk number 119
prepare data
start training
Train on 8029 samples, validate on 2008 samples
Epoch 1/1
8029/8029 [==============================] - 0s - loss: 0.4295 - acc: 0.8164 - val_loss: 0.4264 - val_acc: 0.8118
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-120.h5
chunk number 120
prepare data
start training
Train on 8219 samples, validate on 2055 samples
Epoch 1/1
8219/8219 [==============================] - 0s - loss: 0.4205 - acc: 0.8145 - val_loss: 0.4397 - val_acc: 0.8068
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-121.h5
chunk number 121
prepare data
start training
Train on 8146 samples, validate on 2037 samples
Epoch 1/1
8146/8146 [==============================] - 0s - loss: 0.4329 - acc: 0.8133 - val_loss: 0.4134 - val_acc: 0.8252
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-122.h5
chunk number 122
prepare data
start training
Train on 8128 samples, validate on 2033 samples
Epoch 1/1
8128/8128 [==============================] - 0s - loss: 0.4189 - acc: 0.8155 - val_loss: 0.4033 - val_acc: 0.8244
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-123.h5
chunk number 123
prepare data
start training
Train on 8102 samples, validate on 2026 samples
Epoch 1/1
8102/8102 [==============================] - 0s - loss: 0.4155 - acc: 0.8235 - val_loss: 0.4087 - val_acc: 0.8208
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-124.h5
chunk number 124
prepare data
start training
Train on 8161 samples, validate on 2041 samples
Epoch 1/1
8161/8161 [==============================] - 0s - loss: 0.4268 - acc: 0.8206 - val_loss: 0.4320 - val_acc: 0.8148
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-125.h5
chunk number 125
prepare data
start training
Train on 8209 samples, validate on 2053 samples
Epoch 1/1
8209/8209 [==============================] - 0s - loss: 0.4102 - acc: 0.8211 - val_loss: 0.4090 - val_acc: 0.8222
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-126.h5
chunk number 126
prepare data
start training
Train on 8231 samples, validate on 2058 samples
Epoch 1/1
8231/8231 [==============================] - 0s - loss: 0.4246 - acc: 0.8158 - val_loss: 0.4168 - val_acc: 0.8270
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-127.h5
chunk number 127
prepare data
start training
Train on 8118 samples, validate on 2030 samples
Epoch 1/1
8118/8118 [==============================] - 0s - loss: 0.4215 - acc: 0.8174 - val_loss: 0.4153 - val_acc: 0.8172
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-128.h5
chunk number 128
prepare data
start training
Train on 8164 samples, validate on 2041 samples
Epoch 1/1
8164/8164 [==============================] - 0s - loss: 0.4079 - acc: 0.8302 - val_loss: 0.4001 - val_acc: 0.8295
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-129.h5
chunk number 129
prepare data
start training
Train on 8080 samples, validate on 2021 samples
Epoch 1/1
8080/8080 [==============================] - 0s - loss: 0.4024 - acc: 0.8307 - val_loss: 0.4224 - val_acc: 0.8164
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-130.h5
chunk number 130
prepare data
start training
Train on 8244 samples, validate on 2061 samples
Epoch 1/1
8244/8244 [==============================] - 0s - loss: 0.4127 - acc: 0.8251 - val_loss: 0.3941 - val_acc: 0.8307
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-131.h5
chunk number 131
prepare data
start training
Train on 8130 samples, validate on 2033 samples
Epoch 1/1
8130/8130 [==============================] - 0s - loss: 0.4134 - acc: 0.8189 - val_loss: 0.4165 - val_acc: 0.8205
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-132.h5
chunk number 132
prepare data
start training
Train on 8112 samples, validate on 2029 samples
Epoch 1/1
8112/8112 [==============================] - 0s - loss: 0.4240 - acc: 0.8184 - val_loss: 0.4184 - val_acc: 0.8241
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-133.h5
chunk number 133
prepare data
start training
Train on 8142 samples, validate on 2036 samples
Epoch 1/1
8142/8142 [==============================] - 0s - loss: 0.4400 - acc: 0.8068 - val_loss: 0.4007 - val_acc: 0.8271
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-134.h5
chunk number 134
prepare data
start training
Train on 7998 samples, validate on 2000 samples
Epoch 1/1
7998/7998 [==============================] - 0s - loss: 0.4084 - acc: 0.8247 - val_loss: 0.4202 - val_acc: 0.8220
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-135.h5
chunk number 135
prepare data
start training
Train on 8051 samples, validate on 2013 samples
Epoch 1/1
8051/8051 [==============================] - 0s - loss: 0.4157 - acc: 0.8194 - val_loss: 0.4335 - val_acc: 0.8097
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-136.h5
chunk number 136
prepare data
start training
Train on 8232 samples, validate on 2058 samples
Epoch 1/1
8232/8232 [==============================] - 0s - loss: 0.4218 - acc: 0.8223 - val_loss: 0.4511 - val_acc: 0.7969
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-137.h5
chunk number 137
prepare data
start training
Train on 8052 samples, validate on 2013 samples
Epoch 1/1
8052/8052 [==============================] - 0s - loss: 0.4233 - acc: 0.8191 - val_loss: 0.4181 - val_acc: 0.8202
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-138.h5
chunk number 138
prepare data
start training
Train on 8141 samples, validate on 2036 samples
Epoch 1/1
8141/8141 [==============================] - 0s - loss: 0.4140 - acc: 0.8218 - val_loss: 0.4201 - val_acc: 0.8261
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-139.h5
chunk number 139
prepare data
start training
Train on 8041 samples, validate on 2011 samples
Epoch 1/1
8041/8041 [==============================] - 0s - loss: 0.4238 - acc: 0.8189 - val_loss: 0.4088 - val_acc: 0.8319
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-140.h5
chunk number 140
prepare data
start training
Train on 8171 samples, validate on 2043 samples
Epoch 1/1
8171/8171 [==============================] - 0s - loss: 0.4154 - acc: 0.8211 - val_loss: 0.4247 - val_acc: 0.8184
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-141.h5
chunk number 141
prepare data
start training
Train on 8214 samples, validate on 2054 samples
Epoch 1/1
8214/8214 [==============================] - 0s - loss: 0.4053 - acc: 0.8298 - val_loss: 0.4130 - val_acc: 0.8315
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-142.h5
chunk number 142
prepare data
start training
Train on 8119 samples, validate on 2030 samples
Epoch 1/1
8119/8119 [==============================] - 0s - loss: 0.4237 - acc: 0.8132 - val_loss: 0.4264 - val_acc: 0.8167
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-143.h5
chunk number 143
prepare data
start training
Train on 8183 samples, validate on 2046 samples
Epoch 1/1
8183/8183 [==============================] - 0s - loss: 0.4099 - acc: 0.8240 - val_loss: 0.4201 - val_acc: 0.8196
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-144.h5
chunk number 144
prepare data
start training
Train on 8128 samples, validate on 2033 samples
Epoch 1/1
8128/8128 [==============================] - 0s - loss: 0.4130 - acc: 0.8215 - val_loss: 0.3909 - val_acc: 0.8293
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-145.h5
chunk number 145
prepare data
start training
Train on 8054 samples, validate on 2014 samples
Epoch 1/1
8054/8054 [==============================] - 0s - loss: 0.4156 - acc: 0.8207 - val_loss: 0.4120 - val_acc: 0.8168
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-146.h5
chunk number 146
prepare data
start training
Train on 8129 samples, validate on 2033 samples
Epoch 1/1
8129/8129 [==============================] - 0s - loss: 0.4088 - acc: 0.8269 - val_loss: 0.4224 - val_acc: 0.8101
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-147.h5
chunk number 147
prepare data
start training
Train on 8048 samples, validate on 2012 samples
Epoch 1/1
8048/8048 [==============================] - 0s - loss: 0.4139 - acc: 0.8243 - val_loss: 0.4248 - val_acc: 0.8161
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-148.h5
chunk number 148
prepare data
start training
Train on 8148 samples, validate on 2037 samples
Epoch 1/1
8148/8148 [==============================] - 0s - loss: 0.4176 - acc: 0.8181 - val_loss: 0.4194 - val_acc: 0.8179
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-149.h5
chunk number 149
prepare data
start training
Train on 8118 samples, validate on 2030 samples
Epoch 1/1
8118/8118 [==============================] - 0s - loss: 0.4156 - acc: 0.8224 - val_loss: 0.4179 - val_acc: 0.8232
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-150.h5
chunk number 150
prepare data
start training
Train on 8132 samples, validate on 2033 samples
Epoch 1/1
8132/8132 [==============================] - 0s - loss: 0.4072 - acc: 0.8253 - val_loss: 0.3974 - val_acc: 0.8328
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-151.h5
chunk number 151
prepare data
start training
Train on 8084 samples, validate on 2021 samples
Epoch 1/1
8084/8084 [==============================] - 0s - loss: 0.4214 - acc: 0.8188 - val_loss: 0.4145 - val_acc: 0.8154
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-152.h5
chunk number 152
prepare data
start training
Train on 8093 samples, validate on 2024 samples
Epoch 1/1
8093/8093 [==============================] - 0s - loss: 0.4188 - acc: 0.8228 - val_loss: 0.4034 - val_acc: 0.8370
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-153.h5
chunk number 153
prepare data
start training
Train on 8156 samples, validate on 2039 samples
Epoch 1/1
8156/8156 [==============================] - 0s - loss: 0.4140 - acc: 0.8233 - val_loss: 0.3959 - val_acc: 0.8382
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-154.h5
chunk number 154
prepare data
start training
Train on 8196 samples, validate on 2049 samples
Epoch 1/1
8196/8196 [==============================] - 0s - loss: 0.3995 - acc: 0.8285 - val_loss: 0.4046 - val_acc: 0.8316
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-155.h5
chunk number 155
prepare data
start training
Train on 8090 samples, validate on 2023 samples
Epoch 1/1
8090/8090 [==============================] - 0s - loss: 0.4145 - acc: 0.8272 - val_loss: 0.3950 - val_acc: 0.8280
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-156.h5
chunk number 156
prepare data
start training
Train on 8136 samples, validate on 2034 samples
Epoch 1/1
8136/8136 [==============================] - 0s - loss: 0.4070 - acc: 0.8279 - val_loss: 0.4113 - val_acc: 0.8220
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-157.h5
chunk number 157
prepare data
start training
Train on 8217 samples, validate on 2055 samples
Epoch 1/1
8217/8217 [==============================] - 0s - loss: 0.3911 - acc: 0.8355 - val_loss: 0.4073 - val_acc: 0.8224
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-158.h5
chunk number 158
prepare data
start training
Train on 8188 samples, validate on 2048 samples
Epoch 1/1
8188/8188 [==============================] - 0s - loss: 0.4017 - acc: 0.8312 - val_loss: 0.4089 - val_acc: 0.8237
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-159.h5
chunk number 159
prepare data
start training
Train on 8048 samples, validate on 2012 samples
Epoch 1/1
8048/8048 [==============================] - 0s - loss: 0.3994 - acc: 0.8345 - val_loss: 0.4142 - val_acc: 0.8265
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-160.h5
chunk number 160
prepare data
start training
Train on 8176 samples, validate on 2045 samples
Epoch 1/1
8176/8176 [==============================] - 0s - loss: 0.4091 - acc: 0.8255 - val_loss: 0.4054 - val_acc: 0.8293
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-161.h5
chunk number 161
prepare data
start training
Train on 8105 samples, validate on 2027 samples
Epoch 1/1
8105/8105 [==============================] - 0s - loss: 0.3989 - acc: 0.8321 - val_loss: 0.4024 - val_acc: 0.8308
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-162.h5
chunk number 162
prepare data
start training
Train on 8160 samples, validate on 2040 samples
Epoch 1/1
8160/8160 [==============================] - 0s - loss: 0.4042 - acc: 0.8289 - val_loss: 0.4009 - val_acc: 0.8358
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-163.h5
chunk number 163
prepare data
start training
Train on 8128 samples, validate on 2033 samples
Epoch 1/1
8128/8128 [==============================] - 0s - loss: 0.4086 - acc: 0.8262 - val_loss: 0.3797 - val_acc: 0.8387
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-164.h5
chunk number 164
prepare data
start training
Train on 8118 samples, validate on 2030 samples
Epoch 1/1
8118/8118 [==============================] - 0s - loss: 0.4049 - acc: 0.8269 - val_loss: 0.4086 - val_acc: 0.8271
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-165.h5
chunk number 165
prepare data
start training
Train on 8076 samples, validate on 2020 samples
Epoch 1/1
8076/8076 [==============================] - 0s - loss: 0.4073 - acc: 0.8302 - val_loss: 0.4060 - val_acc: 0.8238
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-166.h5
chunk number 166
prepare data
start training
Train on 8203 samples, validate on 2051 samples
Epoch 1/1
8203/8203 [==============================] - 0s - loss: 0.4072 - acc: 0.8263 - val_loss: 0.3992 - val_acc: 0.8313
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-167.h5
chunk number 167
prepare data
start training
Train on 8100 samples, validate on 2026 samples
Epoch 1/1
8100/8100 [==============================] - 0s - loss: 0.4065 - acc: 0.8274 - val_loss: 0.4047 - val_acc: 0.8342
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-168.h5
chunk number 168
prepare data
start training
Train on 8064 samples, validate on 2016 samples
Epoch 1/1
8064/8064 [==============================] - 0s - loss: 0.4010 - acc: 0.8335 - val_loss: 0.4135 - val_acc: 0.8204
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-169.h5
chunk number 169
prepare data
start training
Train on 8131 samples, validate on 2033 samples
Epoch 1/1
8131/8131 [==============================] - 0s - loss: 0.4108 - acc: 0.8262 - val_loss: 0.4160 - val_acc: 0.8249
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-170.h5
chunk number 170
prepare data
start training
Train on 8132 samples, validate on 2033 samples
Epoch 1/1
8132/8132 [==============================] - 0s - loss: 0.4066 - acc: 0.8275 - val_loss: 0.3897 - val_acc: 0.8377
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-171.h5
chunk number 171
prepare data
start training
Train on 8067 samples, validate on 2017 samples
Epoch 1/1
8067/8067 [==============================] - 0s - loss: 0.4147 - acc: 0.8256 - val_loss: 0.3833 - val_acc: 0.8498
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-172.h5
chunk number 172
prepare data
start training
Train on 8188 samples, validate on 2047 samples
Epoch 1/1
8188/8188 [==============================] - 0s - loss: 0.4064 - acc: 0.8240 - val_loss: 0.4069 - val_acc: 0.8329
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-173.h5
chunk number 173
prepare data
start training
Train on 8166 samples, validate on 2042 samples
Epoch 1/1
8166/8166 [==============================] - 0s - loss: 0.4057 - acc: 0.8251 - val_loss: 0.4269 - val_acc: 0.8115
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-174.h5
chunk number 174
prepare data
start training
Train on 8196 samples, validate on 2049 samples
Epoch 1/1
8196/8196 [==============================] - 0s - loss: 0.4057 - acc: 0.8289 - val_loss: 0.3955 - val_acc: 0.8233
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-175.h5
chunk number 175
prepare data
start training
Train on 7995 samples, validate on 1999 samples
Epoch 1/1
7995/7995 [==============================] - 0s - loss: 0.3907 - acc: 0.8340 - val_loss: 0.4125 - val_acc: 0.8254
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-176.h5
chunk number 176
prepare data
start training
Train on 8116 samples, validate on 2029 samples
Epoch 1/1
8116/8116 [==============================] - 0s - loss: 0.3994 - acc: 0.8350 - val_loss: 0.4165 - val_acc: 0.8255
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-177.h5
chunk number 177
prepare data
start training
Train on 8183 samples, validate on 2046 samples
Epoch 1/1
8183/8183 [==============================] - 0s - loss: 0.4059 - acc: 0.8303 - val_loss: 0.3946 - val_acc: 0.8319
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-178.h5
chunk number 178
prepare data
start training
Train on 8118 samples, validate on 2030 samples
Epoch 1/1
8118/8118 [==============================] - 0s - loss: 0.3934 - acc: 0.8375 - val_loss: 0.4418 - val_acc: 0.8074
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-179.h5
chunk number 179
prepare data
start training
Train on 8117 samples, validate on 2030 samples
Epoch 1/1
8117/8117 [==============================] - 0s - loss: 0.4018 - acc: 0.8301 - val_loss: 0.3950 - val_acc: 0.8379
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-180.h5
chunk number 180
prepare data
start training
Train on 8183 samples, validate on 2046 samples
Epoch 1/1
8183/8183 [==============================] - 0s - loss: 0.4087 - acc: 0.8271 - val_loss: 0.4133 - val_acc: 0.8275
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-181.h5
chunk number 181
prepare data
start training
Train on 8204 samples, validate on 2052 samples
Epoch 1/1
8204/8204 [==============================] - 0s - loss: 0.4096 - acc: 0.8237 - val_loss: 0.3658 - val_acc: 0.8367
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-182.h5
chunk number 182
prepare data
start training
Train on 8163 samples, validate on 2041 samples
Epoch 1/1
8163/8163 [==============================] - 0s - loss: 0.3927 - acc: 0.8384 - val_loss: 0.3902 - val_acc: 0.8368
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-183.h5
chunk number 183
prepare data
start training
Train on 8129 samples, validate on 2033 samples
Epoch 1/1
8129/8129 [==============================] - 0s - loss: 0.4050 - acc: 0.8315 - val_loss: 0.4045 - val_acc: 0.8229
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-184.h5
chunk number 184
prepare data
start training
Train on 8125 samples, validate on 2032 samples
Epoch 1/1
8125/8125 [==============================] - 0s - loss: 0.4065 - acc: 0.8318 - val_loss: 0.3828 - val_acc: 0.8386
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-185.h5
chunk number 185
prepare data
start training
Train on 8141 samples, validate on 2036 samples
Epoch 1/1
8141/8141 [==============================] - 0s - loss: 0.4097 - acc: 0.8268 - val_loss: 0.3815 - val_acc: 0.8350
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-186.h5
chunk number 186
prepare data
start training
Train on 8100 samples, validate on 2026 samples
Epoch 1/1
8100/8100 [==============================] - 0s - loss: 0.4067 - acc: 0.8299 - val_loss: 0.4165 - val_acc: 0.8164
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-187.h5
chunk number 187
prepare data
start training
Train on 8144 samples, validate on 2037 samples
Epoch 1/1
8144/8144 [==============================] - 0s - loss: 0.4030 - acc: 0.8323 - val_loss: 0.3917 - val_acc: 0.8400
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-188.h5
chunk number 188
prepare data
start training
Train on 8091 samples, validate on 2023 samples
Epoch 1/1
8091/8091 [==============================] - 0s - loss: 0.3980 - acc: 0.8341 - val_loss: 0.3957 - val_acc: 0.8211
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-189.h5
chunk number 189
prepare data
start training
Train on 8092 samples, validate on 2023 samples
Epoch 1/1
8092/8092 [==============================] - 0s - loss: 0.4038 - acc: 0.8321 - val_loss: 0.4067 - val_acc: 0.8304
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-190.h5
chunk number 190
prepare data
start training
Train on 8202 samples, validate on 2051 samples
Epoch 1/1
8202/8202 [==============================] - 0s - loss: 0.4024 - acc: 0.8310 - val_loss: 0.4009 - val_acc: 0.8230
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-191.h5
chunk number 191
prepare data
start training
Train on 8144 samples, validate on 2036 samples
Epoch 1/1
8144/8144 [==============================] - 0s - loss: 0.4077 - acc: 0.8260 - val_loss: 0.3874 - val_acc: 0.8399
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-192.h5
chunk number 192
prepare data
start training
Train on 8183 samples, validate on 2046 samples
Epoch 1/1
8183/8183 [==============================] - 0s - loss: 0.4111 - acc: 0.8252 - val_loss: 0.4025 - val_acc: 0.8260
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-193.h5
chunk number 193
prepare data
start training
Train on 8103 samples, validate on 2026 samples
Epoch 1/1
8103/8103 [==============================] - 0s - loss: 0.4018 - acc: 0.8282 - val_loss: 0.3978 - val_acc: 0.8258
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-194.h5
chunk number 194
prepare data
start training
Train on 8133 samples, validate on 2034 samples
Epoch 1/1
8133/8133 [==============================] - 0s - loss: 0.4075 - acc: 0.8225 - val_loss: 0.4020 - val_acc: 0.8338
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-195.h5
chunk number 195
prepare data
start training
Train on 8146 samples, validate on 2037 samples
Epoch 1/1
8146/8146 [==============================] - 0s - loss: 0.4113 - acc: 0.8262 - val_loss: 0.3833 - val_acc: 0.8375
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-196.h5
chunk number 196
prepare data
start training
Train on 8129 samples, validate on 2033 samples
Epoch 1/1
8129/8129 [==============================] - 0s - loss: 0.4075 - acc: 0.8237 - val_loss: 0.3962 - val_acc: 0.8333
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-197.h5
chunk number 197
prepare data
start training
Train on 8259 samples, validate on 2065 samples
Epoch 1/1
8259/8259 [==============================] - 0s - loss: 0.3913 - acc: 0.8338 - val_loss: 0.3986 - val_acc: 0.8339
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-198.h5
chunk number 198
prepare data
start training
Train on 8112 samples, validate on 2028 samples
Epoch 1/1
8112/8112 [==============================] - 0s - loss: 0.3977 - acc: 0.8301 - val_loss: 0.4225 - val_acc: 0.8200
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-199.h5
chunk number 199
prepare data
start training
Train on 8055 samples, validate on 2014 samples
Epoch 1/1
8055/8055 [==============================] - 0s - loss: 0.3951 - acc: 0.8360 - val_loss: 0.3989 - val_acc: 0.8297
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-200.h5
chunk number 200
prepare data
start training
Train on 8092 samples, validate on 2024 samples
Epoch 1/1
8092/8092 [==============================] - 0s - loss: 0.3982 - acc: 0.8321 - val_loss: 0.4065 - val_acc: 0.8281
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-201.h5
chunk number 201
prepare data
start training
Train on 8152 samples, validate on 2039 samples
Epoch 1/1
8152/8152 [==============================] - 0s - loss: 0.4040 - acc: 0.8306 - val_loss: 0.4100 - val_acc: 0.8239
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-202.h5
chunk number 202
prepare data
start training
Train on 8092 samples, validate on 2024 samples
Epoch 1/1
8092/8092 [==============================] - 0s - loss: 0.4012 - acc: 0.8312 - val_loss: 0.4183 - val_acc: 0.8256
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-203.h5
chunk number 203
prepare data
start training
Train on 8183 samples, validate on 2046 samples
Epoch 1/1
8183/8183 [==============================] - 0s - loss: 0.3983 - acc: 0.8263 - val_loss: 0.3880 - val_acc: 0.8324
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-204.h5
chunk number 204
prepare data
start training
Train on 8160 samples, validate on 2041 samples
Epoch 1/1
8160/8160 [==============================] - 0s - loss: 0.4064 - acc: 0.8259 - val_loss: 0.3922 - val_acc: 0.8329
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-205.h5
chunk number 205
prepare data
start training
Train on 8092 samples, validate on 2023 samples
Epoch 1/1
8092/8092 [==============================] - 0s - loss: 0.4007 - acc: 0.8317 - val_loss: 0.3853 - val_acc: 0.8423
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-206.h5
chunk number 206
prepare data
start training
Train on 8142 samples, validate on 2036 samples
Epoch 1/1
8142/8142 [==============================] - 0s - loss: 0.3969 - acc: 0.8301 - val_loss: 0.4230 - val_acc: 0.8153
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-207.h5
chunk number 207
prepare data
start training
Train on 8149 samples, validate on 2038 samples
Epoch 1/1
8149/8149 [==============================] - 0s - loss: 0.4103 - acc: 0.8240 - val_loss: 0.3857 - val_acc: 0.8391
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-208.h5
chunk number 208
prepare data
start training
Train on 8140 samples, validate on 2036 samples
Epoch 1/1
8140/8140 [==============================] - 0s - loss: 0.3996 - acc: 0.8286 - val_loss: 0.3997 - val_acc: 0.8315
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-209.h5
chunk number 209
prepare data
start training
Train on 8209 samples, validate on 2053 samples
Epoch 1/1
8209/8209 [==============================] - 0s - loss: 0.3989 - acc: 0.8329 - val_loss: 0.3890 - val_acc: 0.8451
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-210.h5
chunk number 210
prepare data
start training
Train on 8105 samples, validate on 2027 samples
Epoch 1/1
8105/8105 [==============================] - 0s - loss: 0.4003 - acc: 0.8324 - val_loss: 0.4058 - val_acc: 0.8219
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-211.h5
chunk number 211
prepare data
start training
Train on 8186 samples, validate on 2047 samples
Epoch 1/1
8186/8186 [==============================] - 0s - loss: 0.4049 - acc: 0.8275 - val_loss: 0.4086 - val_acc: 0.8271
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-212.h5
chunk number 212
prepare data
start training
Train on 8195 samples, validate on 2049 samples
Epoch 1/1
8195/8195 [==============================] - 0s - loss: 0.4004 - acc: 0.8289 - val_loss: 0.3972 - val_acc: 0.8263
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-213.h5
chunk number 213
prepare data
start training
Train on 8152 samples, validate on 2038 samples
Epoch 1/1
8152/8152 [==============================] - 0s - loss: 0.3992 - acc: 0.8297 - val_loss: 0.4076 - val_acc: 0.8184
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-214.h5
chunk number 214
prepare data
start training
Train on 8098 samples, validate on 2025 samples
Epoch 1/1
8098/8098 [==============================] - 0s - loss: 0.3888 - acc: 0.8348 - val_loss: 0.3849 - val_acc: 0.8410
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-215.h5
chunk number 215
prepare data
start training
Train on 8174 samples, validate on 2044 samples
Epoch 1/1
8174/8174 [==============================] - 0s - loss: 0.3994 - acc: 0.8295 - val_loss: 0.4020 - val_acc: 0.8297
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-216.h5
chunk number 216
prepare data
start training
Train on 8117 samples, validate on 2030 samples
Epoch 1/1
8117/8117 [==============================] - 0s - loss: 0.4005 - acc: 0.8291 - val_loss: 0.4137 - val_acc: 0.8227
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-217.h5
chunk number 217
prepare data
start training
Train on 8156 samples, validate on 2039 samples
Epoch 1/1
8156/8156 [==============================] - 0s - loss: 0.4157 - acc: 0.8238 - val_loss: 0.3958 - val_acc: 0.8377
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-218.h5
chunk number 218
prepare data
start training
Train on 8087 samples, validate on 2022 samples
Epoch 1/1
8087/8087 [==============================] - 0s - loss: 0.3894 - acc: 0.8373 - val_loss: 0.4053 - val_acc: 0.8309
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-219.h5
chunk number 219
prepare data
start training
Train on 8136 samples, validate on 2035 samples
Epoch 1/1
8136/8136 [==============================] - 0s - loss: 0.4003 - acc: 0.8317 - val_loss: 0.4090 - val_acc: 0.8280
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-220.h5
chunk number 220
prepare data
start training
Train on 8094 samples, validate on 2024 samples
Epoch 1/1
8094/8094 [==============================] - 0s - loss: 0.4039 - acc: 0.8280 - val_loss: 0.4151 - val_acc: 0.8226
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-221.h5
chunk number 221
prepare data
start training
Train on 8005 samples, validate on 2002 samples
Epoch 1/1
8005/8005 [==============================] - 0s - loss: 0.4117 - acc: 0.8247 - val_loss: 0.3950 - val_acc: 0.8332
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-222.h5
chunk number 222
prepare data
start training
Train on 8139 samples, validate on 2035 samples
Epoch 1/1
8139/8139 [==============================] - 0s - loss: 0.4067 - acc: 0.8300 - val_loss: 0.4073 - val_acc: 0.8270
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-223.h5
chunk number 223
prepare data
start training
Train on 8093 samples, validate on 2024 samples
Epoch 1/1
8093/8093 [==============================] - 0s - loss: 0.3972 - acc: 0.8360 - val_loss: 0.3975 - val_acc: 0.8281
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-224.h5
chunk number 224
prepare data
start training
Train on 8124 samples, validate on 2032 samples
Epoch 1/1
8124/8124 [==============================] - 0s - loss: 0.3938 - acc: 0.8364 - val_loss: 0.4085 - val_acc: 0.8278
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-225.h5
chunk number 225
prepare data
start training
Train on 8188 samples, validate on 2047 samples
Epoch 1/1
8188/8188 [==============================] - 0s - loss: 0.3954 - acc: 0.8363 - val_loss: 0.3970 - val_acc: 0.8403
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-226.h5
chunk number 226
prepare data
start training
Train on 8136 samples, validate on 2034 samples
Epoch 1/1
8136/8136 [==============================] - 0s - loss: 0.4001 - acc: 0.8324 - val_loss: 0.4179 - val_acc: 0.8235
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-227.h5
chunk number 227
prepare data
start training
Train on 8170 samples, validate on 2043 samples
Epoch 1/1
8170/8170 [==============================] - 0s - loss: 0.4022 - acc: 0.8293 - val_loss: 0.4152 - val_acc: 0.8223
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-228.h5
chunk number 228
prepare data
start training
Train on 8188 samples, validate on 2047 samples
Epoch 1/1
8188/8188 [==============================] - 0s - loss: 0.3932 - acc: 0.8366 - val_loss: 0.4087 - val_acc: 0.8256
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-229.h5
chunk number 229
prepare data
start training
Train on 8066 samples, validate on 2017 samples
Epoch 1/1
8066/8066 [==============================] - 0s - loss: 0.4069 - acc: 0.8269 - val_loss: 0.3854 - val_acc: 0.8433
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-230.h5
chunk number 230
prepare data
start training
Train on 8096 samples, validate on 2024 samples
Epoch 1/1
8096/8096 [==============================] - 0s - loss: 0.4038 - acc: 0.8302 - val_loss: 0.4084 - val_acc: 0.8231
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-231.h5
chunk number 231
prepare data
start training
Train on 8196 samples, validate on 2049 samples
Epoch 1/1
8196/8196 [==============================] - 0s - loss: 0.3988 - acc: 0.8332 - val_loss: 0.4056 - val_acc: 0.8228
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-232.h5
chunk number 232
prepare data
start training
Train on 8083 samples, validate on 2021 samples
Epoch 1/1
8083/8083 [==============================] - 0s - loss: 0.4000 - acc: 0.8322 - val_loss: 0.3886 - val_acc: 0.8377
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-233.h5
chunk number 233
prepare data
start training
Train on 8077 samples, validate on 2020 samples
Epoch 1/1
8077/8077 [==============================] - 0s - loss: 0.4101 - acc: 0.8233 - val_loss: 0.4058 - val_acc: 0.8272
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-234.h5
chunk number 234
prepare data
start training
Train on 8155 samples, validate on 2039 samples
Epoch 1/1
8155/8155 [==============================] - 0s - loss: 0.3890 - acc: 0.8384 - val_loss: 0.3799 - val_acc: 0.8455
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-235.h5
chunk number 235
prepare data
start training
Train on 8113 samples, validate on 2029 samples
Epoch 1/1
8113/8113 [==============================] - 0s - loss: 0.4032 - acc: 0.8290 - val_loss: 0.3960 - val_acc: 0.8403
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-236.h5
chunk number 236
prepare data
start training
Train on 8135 samples, validate on 2034 samples
Epoch 1/1
8135/8135 [==============================] - 0s - loss: 0.4043 - acc: 0.8275 - val_loss: 0.3658 - val_acc: 0.8520
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-237.h5
chunk number 237
prepare data
start training
Train on 8118 samples, validate on 2030 samples
Epoch 1/1
8118/8118 [==============================] - 0s - loss: 0.4011 - acc: 0.8337 - val_loss: 0.4167 - val_acc: 0.8232
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-238.h5
chunk number 238
prepare data
start training
Train on 8112 samples, validate on 2028 samples
Epoch 1/1
8112/8112 [==============================] - 0s - loss: 0.3943 - acc: 0.8357 - val_loss: 0.3821 - val_acc: 0.8397
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-239.h5
chunk number 239
prepare data
start training
Train on 8073 samples, validate on 2019 samples
Epoch 1/1
8073/8073 [==============================] - 0s - loss: 0.3906 - acc: 0.8395 - val_loss: 0.3859 - val_acc: 0.8405
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-240.h5
chunk number 240
prepare data
start training
Train on 8206 samples, validate on 2052 samples
Epoch 1/1
8206/8206 [==============================] - 0s - loss: 0.3945 - acc: 0.8356 - val_loss: 0.4061 - val_acc: 0.8197
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-241.h5
chunk number 241
prepare data
start training
Train on 8130 samples, validate on 2033 samples
Epoch 1/1
8130/8130 [==============================] - 0s - loss: 0.3902 - acc: 0.8396 - val_loss: 0.4239 - val_acc: 0.8219
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-242.h5
chunk number 242
prepare data
start training
Train on 8116 samples, validate on 2030 samples
Epoch 1/1
8116/8116 [==============================] - 0s - loss: 0.4000 - acc: 0.8284 - val_loss: 0.4753 - val_acc: 0.7862
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-243.h5
chunk number 243
prepare data
start training
Train on 8085 samples, validate on 2022 samples
Epoch 1/1
8085/8085 [==============================] - 0s - loss: 0.4630 - acc: 0.7958 - val_loss: 0.4550 - val_acc: 0.7918
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-244.h5
chunk number 244
prepare data
start training
Train on 8052 samples, validate on 2014 samples
Epoch 1/1
8052/8052 [==============================] - 0s - loss: 0.4536 - acc: 0.7974 - val_loss: 0.4191 - val_acc: 0.8227
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-245.h5
chunk number 245
prepare data
start training
Train on 8131 samples, validate on 2033 samples
Epoch 1/1
8131/8131 [==============================] - 0s - loss: 0.4103 - acc: 0.8196 - val_loss: 0.4458 - val_acc: 0.8037
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-246.h5
chunk number 246
prepare data
start training
Train on 8100 samples, validate on 2025 samples
Epoch 1/1
8100/8100 [==============================] - 0s - loss: 0.4604 - acc: 0.8011 - val_loss: 0.4054 - val_acc: 0.8247
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-247.h5
chunk number 247
prepare data
start training
Train on 8114 samples, validate on 2029 samples
Epoch 1/1
8114/8114 [==============================] - 0s - loss: 0.4103 - acc: 0.8241 - val_loss: 0.4377 - val_acc: 0.8093
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-248.h5
chunk number 248
prepare data
start training
Train on 8124 samples, validate on 2031 samples
Epoch 1/1
8124/8124 [==============================] - 0s - loss: 0.4313 - acc: 0.8055 - val_loss: 0.4283 - val_acc: 0.8154
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-249.h5
chunk number 249
prepare data
start training
Train on 8189 samples, validate on 2048 samples
Epoch 1/1
8189/8189 [==============================] - 0s - loss: 0.4298 - acc: 0.8117 - val_loss: 0.4387 - val_acc: 0.8105
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-250.h5
saving fitted model to /users/phwindis/BTagger/RNN_out/lstm128_1layer_singlestep_250_2/model-final.h5
